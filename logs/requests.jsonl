{"timestamp": "2026-02-15T05:20:30Z", "query": "What is the weather in the San Francisco", "mode": "eco", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=preserve-search-lookup-gate | mode=eco", "model_info": "search:linkup", "latency_ms": 5965.04989099958, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T05:22:02Z", "query": "What is the weather in the San Francisco", "mode": "performance", "tier_name": "Search", "tier_used": 1, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-1", "latency_ms": 376.4963119992899, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T05:22:06Z", "query": "What is the weather in the San Francisco", "mode": "performance", "tier_name": "Search", "tier_used": 1, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-1", "latency_ms": 68.3463240002311, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T05:22:07Z", "query": "What is the weather in the San Francisco", "mode": "performance", "tier_name": "Search", "tier_used": 1, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-1", "latency_ms": 143.03372599897557, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T05:22:11Z", "query": "What is the weather in the San Francisco", "mode": "performance", "tier_name": "Search", "tier_used": 1, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-1", "latency_ms": 9.544586999254534, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T05:22:33Z", "query": "Is the weather cloudy in SF today?", "mode": "performance", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=preserve-search-lookup-gate | mode=performance", "model_info": "search:linkup", "latency_ms": 3031.029543999466, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T05:23:22Z", "query": "what is the history of Silicon Valley?", "mode": "eco", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=score:18 classifier:Search raw:Search resolved:Search | mode=eco", "model_info": "search:linkup", "latency_ms": 6010.114541000803, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T05:23:32Z", "query": "what is the history of Silicon Valley?", "mode": "performance", "tier_name": "Search", "tier_used": 1, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-1", "latency_ms": 74.3361709992314, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T05:23:47Z", "query": "what is the history of West Virginia?", "mode": "performance", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=score:18 classifier:Search raw:Search resolved:Search | mode=performance", "model_info": "search:linkup", "latency_ms": 5905.218419000448, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T05:24:54Z", "query": "Teach me about super position in quantum mechanics", "mode": "performance", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Local | grid=dirty (+15) | thresholds=score:41 classifier:Local raw:Local resolved:Local | mode=performance", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 34572.655145999306, "energy_kwh": 0.001}
{"timestamp": "2026-02-15T05:27:18Z", "query": "teach me about super position in quantum mechanics", "mode": "performance", "tier_name": "Local", "tier_used": 2, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-2", "latency_ms": 24.814808999508386, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T05:29:41Z", "query": "teach me about how the gravitational constant can change as you involve many different large bodies of mass into proximity of each other", "mode": "performance", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Local | grid=dirty (+15) | thresholds=score:41 classifier:Local raw:Local resolved:Local | mode=performance", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 32690.021268001146, "energy_kwh": 0.001}
{"timestamp": "2026-02-15T05:53:32Z", "query": "Design a rigorous proof outline comparing why Transformer self-attention scales quadratically, derive the time/memory complexity formally, and propose two mathematically justified alternatives with tradeoff analysis.", "mode": "eco", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=preserve-forced-gate | mode=eco | adjusted Cloud->Local", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 32190.322349999406, "energy_kwh": 0.0025}
{"timestamp": "2026-02-15T05:58:30Z", "query": "Design a rigorous proof outline comparing why Transformer self-attention scales quadratically, derive the time/memory complexity formally, and propose two mathematically justified alternatives with tradeoff analysis.", "mode": "performance", "tier_name": "Local", "tier_used": 2, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-2", "latency_ms": 2353.3196810003574, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T05:58:49Z", "query": "Design a rigorous proof outline comparing why Transformer self-attention scales exponentially, derive the time/memory complexity formally, and propose two mathematically justified alternatives with tradeoff analysis.", "mode": "performance", "tier_name": "Local", "tier_used": 2, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-2", "latency_ms": 277.7970239985734, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T05:58:52Z", "query": "Design a rigorous proof outline comparing why Transformer self-attention scales exponentially, derive the time/memory complexity formally, and propose two mathematically justified alternatives with tradeoff analysis.", "mode": "performance", "tier_name": "Local", "tier_used": 2, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-2", "latency_ms": 23.757492999720853, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T06:03:15Z", "query": "Provide a formal proof that every finite subgroup of the multiplicative group of a field is cyclic, then generalize the argument to finite subgroups of division rings and discuss where it fails.", "mode": "performance", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=preserve-forced-gate | mode=performance | adjusted Cloud->Local", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 32684.3826789991, "energy_kwh": 0.0025}
{"timestamp": "2026-02-15T06:11:23Z", "query": "Give a formal proof that every finite-dimensional normed vector space over R is complete if and only if all Cauchy sequences converge, and compare the proof structure to the infinite-dimensional case with counterexamples.", "mode": "performance", "tier_name": "Cloud", "tier_used": 3, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=preserve-forced-gate | mode=performance", "model_info": "cloud:gemini-2.5-flash", "latency_ms": 4124.498274999496, "energy_kwh": 0.008}
{"timestamp": "2026-02-15T06:25:55Z", "query": "What color is the grass", "mode": "eco", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=score:18 classifier:Search raw:Search resolved:Search | mode=eco", "model_info": "search:linkup", "latency_ms": 5724.444184001186, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T06:27:17Z", "query": "At a high level, tell me what fluid mechanics is", "mode": "performance", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=score:18 classifier:Search raw:Search resolved:Search | mode=performance", "model_info": "search:linkup", "latency_ms": 3657.723963000535, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T06:28:59Z", "query": "Describe how gradient descent works in training neural networks, including learning rate tradeoffs.", "mode": "performance", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Local | grid=dirty (+15) | thresholds=score:80 classifier:Local raw:Cloud resolved:Cloud | mode=performance | adjusted Cloud->Local", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 30186.569388000862, "energy_kwh": 0.0025}
{"timestamp": "2026-02-15T06:29:57Z", "query": "Design a distributed consensus protocol variant tolerant to Byzantine faults under partial synchrony, and provide safety/liveness proof sketches plus complexity analysis.", "mode": "performance", "tier_name": "Cloud", "tier_used": 3, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=preserve-forced-gate | mode=performance", "model_info": "cloud:gemini-2.5-flash", "latency_ms": 2221.561792999637, "energy_kwh": 0.008}
{"timestamp": "2026-02-15T06:32:11Z", "query": "Prove that every finite-dimensional normed vector space over R is complete, and contrast this with an explicit incomplete infinite-dimensional normed space example.", "mode": "performance", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=preserve-forced-gate | mode=performance | adjusted Cloud->Local", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 31698.972207001134, "energy_kwh": 0.0025}
{"timestamp": "2026-02-15T06:33:03Z", "query": "Give a fully rigorous epsilon-delta proof of the Arzela-Ascoli theorem, then derive a counterexample showing why compactness fails without equicontinuity.", "mode": "performance", "tier_name": "Cloud", "tier_used": 3, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=preserve-forced-gate | mode=performance", "model_info": "cloud:gemini-2.5-flash", "latency_ms": 3872.4959369974385, "energy_kwh": 0.008}
{"timestamp": "2026-02-15T08:46:43Z", "query": "generate me some code for a webserver built with node.js without using the express module", "mode": "eco", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=score:100 classifier:Cloud raw:Cloud resolved:Cloud | mode=eco | adjusted Cloud->Local", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 83020.58219000173, "energy_kwh": 0.0025}
{"timestamp": "2026-02-15T08:49:28Z", "query": "create for me an entire code base for a chat app including both a server and client chat app", "mode": "eco", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=score:100 classifier:Cloud raw:Cloud resolved:Cloud | mode=eco | adjusted Cloud->Local", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 71257.79417599915, "energy_kwh": 0.0025}
{"timestamp": "2026-02-15T09:22:57Z", "query": "create for me an entire code base for a chat app including both a server and client chat app", "mode": "eco", "tier_name": "Local", "tier_used": 2, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-2", "latency_ms": 1855.2864699995553, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T09:23:31Z", "query": "what time is it in london", "mode": "performance", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=preserve-search-lookup-gate | mode=performance", "model_info": "search:linkup", "latency_ms": 3446.0244110014173, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T09:35:06Z", "query": "aaaa", "mode": "eco", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=score:0 classifier:Search raw:Search resolved:Search | mode=eco", "model_info": "search:linkup", "latency_ms": 2793.376798999816, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T09:36:12Z", "query": "how do I install fortnite", "mode": "eco", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Local | grid=dirty (+15) | thresholds=score:66 classifier:Local raw:Local resolved:Local | mode=eco", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 53288.38264300066, "energy_kwh": 0.0025}
{"timestamp": "2026-02-15T09:51:07Z", "query": "what does the dog say", "mode": "eco", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=score:18 classifier:Search raw:Search resolved:Search | mode=eco", "model_info": "search:linkup", "latency_ms": 3662.7060730024823, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T10:20:16Z", "query": "what does the fox say", "mode": "eco", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=score:18 classifier:Search raw:Search resolved:Search | mode=eco", "model_info": "search:linkup", "latency_ms": 5173.797278002894, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T10:20:42Z", "query": "what does the foxy say", "mode": "eco", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=score:18 classifier:Search raw:Search resolved:Search | mode=eco", "model_info": "search:linkup", "latency_ms": 4094.0231419990596, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T10:21:18Z", "query": "generate me code for a webserver made with node.js without express and without http module", "mode": "eco", "tier_name": "Local", "tier_used": 2, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-2", "latency_ms": 37.93026700077462, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T10:23:11Z", "query": "generate code for me that implements a PID controller in C", "mode": "eco", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=score:100 classifier:Cloud raw:Cloud resolved:Cloud | mode=eco | adjusted Cloud->Local", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 81385.49760800015, "energy_kwh": 0.0025}
{"timestamp": "2026-02-15T10:29:52Z", "query": "Prove that for any prime number p, there exists a prime q such that q > p", "mode": "eco", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=preserve-forced-gate | mode=eco | adjusted Cloud->Local", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 41931.46793699998, "energy_kwh": 0.0025}
{"timestamp": "2026-02-15T10:42:23Z", "query": "Prove that for any prime number p, there exists a prime q such that q > p", "mode": "eco", "tier_name": "Local", "tier_used": 2, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-2", "latency_ms": 1749.0874679970148, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T11:15:28Z", "query": "generate me code for me that is text based adventure written in python", "mode": "performance", "tier_name": "Cloud", "tier_used": 3, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=score:100 classifier:Cloud raw:Cloud resolved:Cloud | mode=performance", "model_info": "cloud:gemini-2.5-flash", "latency_ms": 4884.690674000012, "energy_kwh": 0.008}
{"timestamp": "2026-02-15T11:17:07Z", "query": "generate me code for an autoclicker written in C and give me the command to activate it in powershell", "mode": "eco", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=score:100 classifier:Cloud raw:Cloud resolved:Cloud | mode=eco | adjusted Cloud->Local", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 64104.56623400023, "energy_kwh": 0.0025}
{"timestamp": "2026-02-15T11:26:25Z", "query": "what time is it in south africa", "mode": "performance", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=preserve-search-lookup-gate | mode=performance", "model_info": "search:linkup", "latency_ms": 5257.410178997816, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T11:35:54Z", "query": "what is 1+1", "mode": "eco", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=score:18 classifier:Search raw:Search resolved:Search | mode=eco", "model_info": "search:linkup", "latency_ms": 4417.180323998764, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T12:33:33Z", "query": "what do you do when you are bit by a badger", "mode": "performance", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=score:44 classifier:Search raw:Local resolved:Local | mode=performance", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 26362.38687200239, "energy_kwh": 0.0025}
{"timestamp": "2026-02-15T12:34:23Z", "query": "what language do they speak in france", "mode": "performance", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=score:18 classifier:Search raw:Search resolved:Search | mode=performance", "model_info": "search:linkup", "latency_ms": 6085.618734003219, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T12:34:59Z", "query": "generate me code for a Keylogger in C", "mode": "performance", "tier_name": "Cloud", "tier_used": 3, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=score:100 classifier:Cloud raw:Cloud resolved:Cloud | mode=performance", "model_info": "cloud:gemini-2.5-flash", "latency_ms": 2900.576412997907, "energy_kwh": 0.008}
{"timestamp": "2026-02-15T12:39:49Z", "query": "what is a yo-yo", "mode": "eco", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=score:18 classifier:Search raw:Search resolved:Search | mode=eco", "model_info": "search:linkup", "latency_ms": 4803.048596004373, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T12:40:49Z", "query": "generate me code for a PID controller written in C", "mode": "performance", "tier_name": "Local", "tier_used": 2, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-2", "latency_ms": 32.38391199556645, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T12:41:33Z", "query": "Generate me code that can sort a database of questions into search, local, and cloud", "mode": "performance", "tier_name": "Cloud", "tier_used": 3, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=score:100 classifier:Cloud raw:Cloud resolved:Cloud | mode=performance", "model_info": "cloud:gemini-2.5-flash", "latency_ms": 3464.0414609966683, "energy_kwh": 0.008}
{"timestamp": "2026-02-15T12:57:22Z", "query": "Generate me code that can sort a database of questions into search, local, and cloud", "mode": "performance", "tier_name": "Cloud", "tier_used": 3, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-3", "latency_ms": 1828.7331140018068, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T13:02:27Z", "query": "what is 1+1", "mode": "eco", "tier_name": "Search", "tier_used": 1, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-1", "latency_ms": 1976.6365309988032, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T13:02:55Z", "query": "generate me code for a PID controller in C", "mode": "performance", "tier_name": "Local", "tier_used": 2, "cached": true, "was_escalated": false, "routing_reason": "Semantic cache hit (similar query answered before)", "model_info": "cache:tier-2", "latency_ms": 30.896153002686333, "energy_kwh": 0.0}
{"timestamp": "2026-02-15T13:03:41Z", "query": "Generate code for my AI chatbot that will make API calls to gemini", "mode": "performance", "tier_name": "Cloud", "tier_used": 3, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=score:100 classifier:Cloud raw:Cloud resolved:Cloud | mode=performance", "model_info": "cloud:error:Error making API call: 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-2-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}", "latency_ms": 1767.0048479994875, "energy_kwh": 0.008}
{"timestamp": "2026-02-15T13:08:19Z", "query": "What is 1+1", "mode": "eco", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=score:18 classifier:Search raw:Search resolved:Search | mode=eco", "model_info": "search:linkup", "latency_ms": 4531.882033996226, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T13:10:33Z", "query": "give me a recipe for an apple pie", "mode": "eco", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Local | grid=dirty (+15) | thresholds=score:98 classifier:Local raw:Cloud resolved:Cloud | mode=eco | adjusted Cloud->Local", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 97579.40007700381, "energy_kwh": 0.0025}
{"timestamp": "2026-02-15T13:11:15Z", "query": "Generate code for a PID controller in C", "mode": "performance", "tier_name": "Cloud", "tier_used": 3, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=score:100 classifier:Cloud raw:Cloud resolved:Cloud | mode=performance", "model_info": "cloud:error:Error making API call: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\\nPlease retry in 44.267135099s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '44s'}]}}", "latency_ms": 1716.4154990023235, "energy_kwh": 0.008}
{"timestamp": "2026-02-15T13:21:08Z", "query": "what is 1+1", "mode": "eco", "tier_name": "Search", "tier_used": 1, "cached": false, "was_escalated": false, "routing_reason": "Classified as Search | grid=dirty (+15) | thresholds=score:18 classifier:Search raw:Search resolved:Search | mode=eco", "model_info": "search:linkup", "latency_ms": 4649.0428459947, "energy_kwh": 0.0001}
{"timestamp": "2026-02-15T13:23:17Z", "query": "explain to me what the pythagoras theorem is", "mode": "eco", "tier_name": "Local", "tier_used": 2, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=preserve-forced-gate | mode=eco | adjusted Cloud->Local", "model_info": "local:executorch:larryliu0820/Qwen3-1.7B-INT8-INT4-ExecuTorch-XNNPACK", "latency_ms": 81529.97300200514, "energy_kwh": 0.0025}
{"timestamp": "2026-02-15T13:23:53Z", "query": "generate me code for a PID controller in C", "mode": "performance", "tier_name": "Cloud", "tier_used": 3, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=score:100 classifier:Cloud raw:Cloud resolved:Cloud | mode=performance", "model_info": "cloud:error:Error making API call: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\\nPlease retry in 6.894108289s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '6s'}]}}", "latency_ms": 1710.7512059956207, "energy_kwh": 0.008}
{"timestamp": "2026-02-15T13:24:49Z", "query": "Generate me code for a keylogger", "mode": "performance", "tier_name": "Cloud", "tier_used": 3, "cached": false, "was_escalated": false, "routing_reason": "Classified as Cloud | grid=dirty (+15) | thresholds=score:100 classifier:Cloud raw:Cloud resolved:Cloud | mode=performance", "model_info": "cloud:error:Error making API call: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\\nPlease retry in 10.159377007s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.0-flash', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.0-flash'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}", "latency_ms": 213.33395699912217, "energy_kwh": 0.008}
